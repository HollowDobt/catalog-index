"""
# src/domians/agents/agent.py

Define the functions corresponding to all states and wrap them in the core class IntelligentResearchAgent

å®šä¹‰æ‰€æœ‰çŠ¶æ€å¯¹åº”çš„å‡½æ•°ä¸çŠ¶æ€é—´å…³ç³», åŒ…è£…åœ¨æ ¸å¿ƒç±» IntelligentResearchAgent ä¸­
"""


from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue
import logging

from src.infrastructure import (
    RateLimiter,
    LLMClient,
    AcademicDBAPIGenerator,
    AcademicDBClient,
    Mem0Client,
    PDFToMarkdownConverter,
    ArticleStructuring
)
from src.config import CONFIG
from src.domains.agents.agent_states import ActionType, AgentState
from src.domains.entities import ExecutionContext
from src.domains.services import (
    evaluate_search_quality,
    generate_adaptive_keywords,
    intelligent_synthesis_merge,
    find_connect,
    evaluate_abstract_relevance
)


logger = logging.getLogger(__name__)

ADB_rate_limiter = RateLimiter(min_interval=CONFIG["ADB_RATE_LIMITER"])


class IntelligentResearchAgent:
    """
    Advanced AI Agent with state-based planning and adaptive execution
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Minimum parameters provided: front-end interactive interface,
        original paper processing LLM, API generator, embedding model
        """
        self.config = config

        # State Log -> context
        self.context = ExecutionContext(
            current_state=AgentState.INITIALIZING,
            search_attempts=0,
            total_papers_found=0,
            processed_papers=0,
            successful_analyses=0,
            failed_analyses=0,
            current_keywords="",
            user_query="",
        )

        # Initialize clients
        self.llm_query_processor = LLMClient.create(
            config["raw_message_process_llm"],
            model=config["raw_message_process_llm_model"],
        )
        self.llm_api_generator = LLMClient.create(
            config["api_generate_llm"], model=config["api_generate_llm_model"]
        )
        self.llm_embedding = LLMClient.create(
            config["embedding_llm"], model=config["embedding_llm_model"]
        )

        # Initialize tools
        self.api_rag = AcademicDBAPIGenerator.create("arxiv", LLM_client=self.llm_api_generator)
        self.metadata_client = AcademicDBClient.create("arxiv")
        self.memory = Mem0Client()
        self.pdf_parser = PDFToMarkdownConverter()
        self.article_processor = ArticleStructuring(
            llm=config["raw_message_process_llm"],
            llm_model=config["raw_message_process_llm_model"],
        )

        # Thread management
        # self.max_workers = config.get("max_workers_llm", 8)
        self.result_queue = queue.Queue()

        # Agent decision system
        # State Mapping Table: From state to function
        self.state_handlers = {
            AgentState.INITIALIZING: self._handle_initialization,
            AgentState.ANALYZING_QUERY: self._handle_query_analysis,
            AgentState.PLANNING_SEARCH: self._handle_search_planning,
            AgentState.EXECUTING_SEARCH: self._handle_search_execution,
            AgentState.PROCESSING_RESULTS: self._handle_result_processing,
            AgentState.EVALUATING_RESULTS: self._handle_result_evaluation,
            AgentState.REFINING_STRATEGY: self._handle_strategy_refinement,
            AgentState.SYNTHESIZING: self._handle_synthesis,
        }
    
    def _transition_state(
        self, new_state: AgentState, context_data: Optional[Dict[str, Any]] = None
    ):
        """
        Handle state transitions with logging
        """
        # Record the current status and then update the current status for the next step
        old_state = self.context.current_state
        self.context.current_state = new_state

        # Prepare log data. If context_data is None, use None
        transition_details = {
            "from_state": getattr(old_state, "name", None),
            "to_state": getattr(old_state, "name", None),
            "context_data": context_data,
        }

        logger.info(f"Agent State Changes: {old_state.name} â†’ {new_state.name}")
        self.context.add_execution_record(ActionType.QUERY_ANALYSIS, transition_details)
        
        
    ### STATE FUNCTION
    # Startup Function
    def _handle_initialization(self) -> AgentState:
        """
        Initialize the agent and gather user input
        """
        logger.info("â½â½Ù©(à¹‘ËƒÌ¶ÍˆÌ€ á—¨ Ë‚Ì¶ÍˆÌ)Û¶â¾â¾ Library Index has been launched")

        user_query = input("â½â½Ù©(à¹‘ËƒÌ¶ÍˆÌ€ á—¨ Ë‚Ì¶ÍˆÌ)Û¶â¾â¾ ç§‘ç ”äºº, ä»Šå¤©ä½ æ¥æ­¤åœ°æ˜¯ä¸ºäº†å¯»æ‰¾ä»€ä¹ˆ?")
        self.context.user_query = user_query

        # Logging
        self.context.add_execution_record(
            action=ActionType.QUERY_ANALYSIS,
            details={"user_query": user_query, "summary": "ç”¨æˆ·å·²å‘é€æ£€ç´¢è¯·æ±‚"},
        )

        return AgentState.ANALYZING_QUERY
    
    
    ### STATE FUNCTION
    # Keyword generation function
    def _handle_query_analysis(self) -> AgentState:
        """
        Analyze user query and generate initial keywords
        """
        logger.info("(*Ë‡Ï‰Ë‡*äºº) Generating keywords...")

        analysis_prompt = """
ä½ æ˜¯ä¸€ä¸ªç§‘ç ”æŸ¥è¯¢åˆ†æä¸“å®¶ã€‚åˆ†æç”¨æˆ·çš„ç ”ç©¶é—®é¢˜ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æœç´¢å…³é”®è¯ã€‚

## è¦æ±‚ï¼š
    1. æå–æ ¸å¿ƒç ”ç©¶æ¦‚å¿µå’Œæ–¹æ³•
    2. è¯†åˆ«ç›¸å…³ç ”ç©¶é¢†åŸŸå’Œå­é¢†åŸŸ
    3. ç”Ÿæˆå¤šæ ·åŒ–çš„å…³é”®è¯ç»„åˆ
    4. è€ƒè™‘æŠ€æœ¯æœ¯è¯­å’Œé€šç”¨æœ¯è¯­çš„å¹³è¡¡
    5. è¾“å‡ºæ ¼å¼ï¼šä»…è¾“å‡ºå…³é”®è¯ï¼Œç”¨å¥å·åˆ†å‰²
"""

        message = [
            {"role": "system", "content": analysis_prompt},
            {"role": "user", "content": self.context.user_query},
        ]

        response = self.llm_query_processor.chat_completion(
            messages=message, temperature=0.7
        )

        initial_keywords = response["choices"][0]["message"]["content"]
        self.context.current_keywords = initial_keywords

        # Show generated keywords to user for feedback
        print(
            f"(*Ë‡Ï‰Ë‡*äºº) è¿™äº›æ£€ç´¢å¯¹è±¡æ˜¯å¦è¶³å¤Ÿäº†? ä¸å¤Ÿè¯·ç»§ç»­è¡¥å……, æˆ‘ä¼šå¸¦ä¸Šä¸€èµ·æ‰¾: \n**{initial_keywords}**"
        )
        additional_keywords = input(
            "(ç›´æ¥è¾“å…¥å…³é”®è¯, ç”¨é€—å·åˆ†å‰², æˆ–æŒ‰å›è½¦è·³è¿‡)"
        )

        if additional_keywords.strip():
            self.context.current_keywords += ", " + additional_keywords

        # Logging
        self.context.add_execution_record(
            action=ActionType.KEYWORD_GENERATION,
            details={
                "initial_keywords": initial_keywords,
                "additional_keywords": additional_keywords,
                "final_keywords": self.context.current_keywords,
                "summary": "å…³é”®è¯ç”Ÿæˆå®Œæˆ",
            },
        )

        return AgentState.PLANNING_SEARCH
    
    
    ### STATE FUNCTION
    # Function for accessing code generation
    def _handle_search_planning(self) -> AgentState:
        """
        Plan the search strategy based on current context
        """
        logger.info("â•®(â•¯âˆ€â•°)â•­ Planning a search strategy...")

        api_queries = self.api_rag.api_coding(self.context.current_keywords)

        search_plan = {
            "total_queries": len(api_queries),
            "max_papers_per_query": CONFIG["ADB_SEARCH_MAX_RESULTS"],
            "expected_total_papers": len(api_queries) * CONFIG["ADB_SEARCH_MAX_RESULTS"],
            "search_strategy": "systematic_parallel",
        }

        logger.info(
            f"Search Plan: In total *{search_plan['total_queries']}*, expected *{search_plan['expected_total_papers']}* papers"
        )

        # Logging
        self.context.add_execution_record(
            action=ActionType.SEARCH_EXECUTION,
            details={
                "api_queries": api_queries,
                "search_plan": search_plan,
                "summary": f"ç”Ÿæˆ {len(api_queries)} ä¸ªæœç´¢æŸ¥è¯¢",
            },
        )

        # Store queries in context for execution
        self.context.search_results = [
            {"query": query, "status": "pending"} for query in api_queries
        ]

        return AgentState.EXECUTING_SEARCH
    
    
    ### STATE FUNCTION
    # Function for searching through accessing code
    def _handle_search_execution(self) -> AgentState:
        """
        Execute the planned searches
        """
        logger.info("ÎµÙ©(à¹‘> â‚ƒ <)Û¶Ğ· Executing search strategies...")

        all_metadata: List[Dict[str, Any]] = []
        papers_found_in_attempt = False

        for i, search_item in enumerate(self.context.search_results):
            if search_item["status"] != "pending":
                continue

            query = search_item["query"]
            logger.info(f"[{i+1}/{len(self.context.search_results)}] Execute query: *{query}*")

            ADB_rate_limiter.wait_if_needed()

            try:
                metadata_list = self.metadata_client.search_get_metadata(
                    query=query, max_num=CONFIG["ADB_SEARCH_MAX_RESULTS"]
                )

                # Retrieve available results
                if metadata_list:
                    papers_found_in_attempt = True
                    all_metadata.extend(metadata_list)
                    search_item["status"] = "completed"
                    search_item["results"] = metadata_list
                    logger.info(f"  âœ“ Found articles number: {len(metadata_list)}")
                # No available results
                else:
                    search_item["status"] = "no_results"
                    logger.warning(f"  âš  No metadata found")

            except Exception as exc:
                search_item["status"] = "error"
                search_item["error"] = str(exc)
                logger.warning(f"Retrieval failed. Details: {exc}")

        # Logging
        self.context.total_papers_found = len(all_metadata)
        self.context.search_attempts += 1
        self.context.add_execution_record(
            action=ActionType.SEARCH_EXECUTION,
            details={
                "papers_found": len(all_metadata),
                "attempt_number": self.context.search_attempts,
                "summary": f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(all_metadata)} ç¯‡è®ºæ–‡",
            },
        )

        # Store metadata for processing
        self.all_metadata = all_metadata

        if papers_found_in_attempt:
            return AgentState.PROCESSING_RESULTS
        else:
            return AgentState.EVALUATING_RESULTS
    
    
    def _process_single_paper(self, meta: Dict[str, Any]) -> None:
        """
        Process a single paper with error handling
        """
        try:
            ADB_rate_limiter.wait_if_needed()
            raw_article_address = self.metadata_client.single_metadata_parser(meta)

            # Analyze the article
            ana_article = self.article_processor.analyze(
                self.pdf_parser.convert(raw_article_address).markdown_text
            )
            self.memory.add_memory(messages=ana_article, metadata={"id": meta["id"]})

            # Find connections
            self.result_queue.put(
                find_connect(
                    llm_embedding=self.llm_embedding ,article=ana_article, user_query=self.context.user_query
                )
            )
            self.context.successful_analyses += 1
            logger.info(f"Successfully processed: {meta['id']}")

        except Exception as exc:
            error_message = f"Processing failed (ID: {meta['id']}): {exc}"
            self.result_queue.put(error_message)
            self.context.failed_analyses += 1
            logger.warning(f"{error_message}")
    
    
    ### STATE FUNCTION
    # Structuring the paper into prompt words
    def _handle_result_processing(self) -> AgentState:
        """
        Process the found papers using LLM analysis
        """
        logger.info("ãƒ¾(â—ã‚œâ–½ã‚œâ—)â™¡ Processing paper content...")

        if not hasattr(self, "all_metadata") or not self.all_metadata:
            logger.warning("No metadata found")
            return AgentState.EVALUATING_RESULTS
        
        # Filter papers by abstract relevance first
        relevant_metadata: List[Dict[str, Any]] = []
        filtered_count = 0
        
        for meta in self.all_metadata:
            paper_id = meta.get("id", "unknown")
            abstract = meta.get("summary", "")
            
            if not abstract.strip():
                logger.warning(f"No abstract found for paper {paper_id}, skipping relevance check")
                relevant_metadata.append(meta)
                continue
            
            # Evaluate abstract relevance
            try:
                relevance_score = evaluate_abstract_relevance(
                    llm_embedding=self.llm_embedding,
                    abstract=abstract,
                    user_query=self.context.user_query
                )
                
                if relevance_score >= CONFIG["MINIMUM_RELEVANCE_THRESHOLD"]:
                    relevant_metadata.append(meta)
                    logger.info(f"Paper {paper_id} passed relevance filter (score: {relevance_score:.2f})")
                else:
                    filtered_count += 1
                    logger.info(f"Paper {paper_id} filtered out (score: {relevance_score:.2f} < {CONFIG['MINIMUM_RELEVANCE_THRESHOLD']})")
                    
            except Exception as exc:
                logger.warning(f"Error evaluating relevance for {paper_id}: {exc}, including paper anyway")
                relevant_metadata.append(meta)
        
        logger.info(f"Abstract relevance filtering: {len(relevant_metadata)} papers passed, {filtered_count} filtered out")
        
        if not relevant_metadata:
            logger.warning("No papers passed relevance filtering")
            return AgentState.EVALUATING_RESULTS
        
        with ThreadPoolExecutor(
            max_workers=CONFIG["MAX_WORKERS"], thread_name_prefix="LI-llm_worker"
        ) as executor:
            futures = []

            for meta in relevant_metadata:
                logger.info(f"ãƒ¾(â—ã‚œâ–½ã‚œâ—)â™¡ Processing papers: {meta.get('id', 'unknown')}")

                # Check memory first
                cached_analysis = self.memory.search_metadata(meta["id"])
                if cached_analysis:
                    logger.info("âœ“ Get analysis results from the memory layer")
                    try:
                        result = find_connect(
                            llm_embedding=self.llm_embedding,
                            article=cached_analysis[0]["memory"],
                            user_query=self.context.user_query
                        )
                        self.result_queue.put(result)
                        self.context.successful_analyses += 1
                    except Exception as exc:
                        self.result_queue.put(
                            f"è®°å¿†å±‚å¤„ç†é”™è¯¯ (ID: {meta['id']}): {exc}"
                        )
                        self.context.failed_analyses += 1
                        logger.warning(f"Memory layer processing errors (ID: {meta['id']}): {exc}")

                # Direct parsing of non-indexed content in the memory layer
                else:
                    # Submit to process
                    future = executor.submit(self._process_single_paper, meta)
                    futures.append(future)

            # Wait for all processing to complete
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as exc:
                    logger.warning(f"Paper processing failed: {exc}")

        self.context.processed_papers = len(relevant_metadata)

        # Logging
        self.context.add_execution_record(
            action=ActionType.RESULT_PROCESSING,
            details={
                "total_found": len(self.all_metadata),
                "filtered_by_relevance": filtered_count,
                "total_processed": self.context.processed_papers,
                "successful": self.context.successful_analyses,
                "failed": self.context.failed_analyses,
                "relevance_threshold": CONFIG["MINIMUM_RELEVANCE_THRESHOLD"],
                "summary": f"å¤„ç†å®Œæˆï¼šé€šè¿‡ç›¸å…³æ€§è¿‡æ»¤ {len(relevant_metadata)}/{len(self.all_metadata)} ç¯‡ï¼ŒæˆåŠŸåˆ†æ {self.context.successful_analyses}/{self.context.processed_papers} ç¯‡",
            },
        )

        return AgentState.EVALUATING_RESULTS
    
    
    ### STATE FUNCTION
    # Evaluator for search results
    def _handle_result_evaluation(self) -> AgentState:
        """
        Evaluate the quality of results and decide next action
        """
        logger.info("à¸…â—Ï‰â—à¸… Evaluate search result quality...")

        evaluation = evaluate_search_quality(self.context)

        print(f"  ğŸ“ˆ è¯„ä¼°ç»“æœï¼š")
        print(f"    - æ‰¾åˆ°è®ºæ–‡: {evaluation['papers_found']}")
        print(f"    - æˆåŠŸç‡: {evaluation['success_rate']:.2%}")
        print(f"    - æœç´¢æ•ˆç‡: {evaluation['search_efficiency']:.2f}")
        print(f"    - å»ºè®®è¡ŒåŠ¨: {evaluation['suggested_action']}")

        # Logging
        self.context.add_execution_record(
            action=ActionType.STRATEGY_REFINEMENT,
            details={
                "evaluation": evaluation,
                "summary": f"è¯„ä¼°å®Œæˆï¼Œå»ºè®®: {evaluation['suggested_action']}",
            },
        )

        if (
            evaluation["needs_refinement"]
            and self.context.search_attempts < CONFIG[""]
        ):
            return AgentState.REFINING_STRATEGY
        else:
            return AgentState.SYNTHESIZING
        
        
    ### STATE FUNCTION
    # Avoid generating the same keywords and regenerate based on it
    def _handle_strategy_refinement(self) -> AgentState:
        """
        Refine search strategy based on evaluation
        """
        logger.info("â–¼ãƒ»á´¥ãƒ»â–¼ Optimize search strategy...")

        evaluation = evaluate_search_quality(self.context)
        new_keywords = generate_adaptive_keywords(evaluation=evaluation, context=self.context, llm_query_processor=self.llm_query_processor)

        logger.info(f"à¸…^â€¢ï»Œâ€¢^à¸… Keyword optimization: Original keywords: {self.context.current_keywords}; New Keywords: {new_keywords}")

        self.context.current_keywords = new_keywords

        # Logging
        self.context.add_execution_record(
            action=ActionType.STRATEGY_REFINEMENT,
            details={
                "old_keywords": self.context.current_keywords,
                "new_keywords": new_keywords,
                "summary": "å®Œæˆæœç´¢ç­–ç•¥ä¼˜åŒ–",
            },
        )

        return AgentState.PLANNING_SEARCH
    
    
    ### STATE FUNCTION
    # Combining all the previous papers to generate the final results with intelligent synthesis
    def _handle_synthesis(self) -> AgentState:
        """
        Synthesize all results using intelligent binary-merge algorithm and present to user
        """
        logger.info("o(â˜†Ğ¤âˆ‡Ğ¤â˜†)o Comprehensive analysis results...")

        # Collect all results
        results = []
        while not self.result_queue.empty():
            results.append(self.result_queue.get())

        self.context.analysis_results = results

        if results:
            logger.info(f"(ï¼Šã‚œãƒ¼ã‚œ)b Collecting analysis results(NUM): {len(results)}; Start integrating all the information...")

            # Use intelligent synthesis merge instead of simple concatenation
            intelligently_merged_content = intelligent_synthesis_merge(results, context=self.context, llm_query_processor=self.llm_query_processor, max_workers=CONFIG["MAX_WORKERS"])

            synthesis_summary = f"""

# ğŸ¯ æ™ºåº“ç´¢å¼•æ‰§è¡ŒæŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ¦‚å†µ
- æŸ¥è¯¢åˆ†æ: âœ“
- æœç´¢å°è¯•: {self.context.search_attempts} æ¬¡
- æ‰¾åˆ°è®ºæ–‡: {self.context.total_papers_found} ç¯‡
- æˆåŠŸåˆ†æ: {self.context.successful_analyses} ç¯‡
- åˆ†ææˆåŠŸç‡: {(self.context.successful_analyses/max(1,self.context.processed_papers)):.1%}

## ğŸ“š ç ”ç©¶å‘ç°
{intelligently_merged_content}
"""
            print("âœ¨ å…¨æ•´åˆå®Œæˆ")
            print(synthesis_summary)

        else:
            no_result_message = f"""
# ğŸ¯ æ™ºåº“ç´¢å¼•æ‰§è¡ŒæŠ¥å‘Š

ç»è¿‡ {self.context.search_attempts} æ¬¡æ™ºèƒ½æœç´¢å°è¯•ï¼Œæœªèƒ½æ‰¾åˆ°ä¸æ‚¨çš„æŸ¥è¯¢ç›´æ¥ç›¸å…³çš„é«˜è´¨é‡è®ºæ–‡ã€‚

## å»ºè®®
1. å°è¯•æ›´é€šç”¨æˆ–ç›¸å…³çš„å…³é”®è¯
2. æ‰©å±•æœç´¢åˆ°ç›¸å…³ç ”ç©¶é¢†åŸŸ
3. æ£€æŸ¥æŸ¥è¯¢çš„å…·ä½“æ€§æ˜¯å¦åˆé€‚
"""
            print(no_result_message)

        # Logging
        self.context.add_execution_record(
            action=ActionType.SYNTHESIS,
            details={
                "total_results": len(results),
                "execution_summary": {
                    "search_attempts": self.context.search_attempts,
                    "papers_found": self.context.total_papers_found,
                    "successful_analyses": self.context.successful_analyses,
                },
                "summary": "å·²å®Œæˆè§£æä¸æç¤ºè¯ç´¢å¼•ç”Ÿæˆ",
            },
        )

        return AgentState.COMPLETED